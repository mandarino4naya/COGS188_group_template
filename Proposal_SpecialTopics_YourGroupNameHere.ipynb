{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Special Topics Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Rina Pecherskaya\n",
    "- Mabel Szeto "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic and outline\n",
    "\n",
    "### Main topic\n",
    "Bringing machine learning methods full circle, many algorithms have been designed based on our understanding of how the human brain works and now these algorithms coupled with deep brain stimulation (DBS) are used as interventions for neurological disorders.\n",
    "\n",
    "### Learning goal for students \n",
    "Students will be able to evaluate the strengths and limitations of using reinforcement learning-based frameworks in Deep Brain Stimulation (DBS) therapy.\n",
    "\n",
    "\n",
    "### Outline of the topic\n",
    "  - Simulation-Based RL Framework for Developing Neuronal Treatments \n",
    "    - __Simulated environments like the RL gym framework enable the testing and optimization of neuronal suppression strategies without invasive procedures__  \n",
    "    - Another less important element \n",
    "  - Reinforcement Learning in Deep Brain Stimulation (DBS) Therapy\n",
    "    - __The actor-critic RL architecture mimics the Basal Ganglia’s function, enhancing the biological relevance of the model__ \n",
    "    - Basal Ganglia Reinforcement Learning (BGRL) is a closed-loop, personalizable DBS system that reduces neural synchrony more effectively than standard RL models\n",
    "  - Virtual Animal Model for Understanding Motor Behavior and Neural Control\n",
    "    - __Using a virtual animal model that models both neural activity and the resulting behaviors seen in the world helps bridge theoretical principles like motor control (inverse dynamics) with observed neural variability__\n",
    "    - Neural activity in the sensorimotor striatum and motor cortex is better explained by virtual rodent network activity than by physical movement features\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedagogy\n",
    "\n",
    "\n",
    "### Readings\n",
    "\n",
    "<a name=\"krylovnote\"></a> Krylov, D., Tachet, R., Laroche, R., Rosenblum, M., & Dylov, D. V. (2020). Reinforcement learning framework for deep brain stimulation study. arXiv preprint arXiv:2002.10948. https://arxiv.org/abs/2002.10948<br> \n",
    "\n",
    "This paper explores how pathologically synchronous neurons may contribute to the symptoms of neurological diseases like Parkinson’s. These synchronized neuronal networks are hypothesized to cause tremors, rigidity, and other motor abnormalities. While Deep Brain Stimulation (DBS) devices at the time of publication use high-frequency, open-loop pulses without feedback mechanisms, they may not be optimally tuned to each patient’s needs due to the limitations of human experimentation (DBS works via implanted micro-electrodes) and the complexity of the brain’s non-linear systems.\n",
    "\n",
    "The authors introduce a novel RL gym environment that simulates various pathological neuronal models, allowing researchers to test and optimize RL algorithms for synchrony suppression. They demonstrate the successful suppression of regular, chaotic, and bursting oscillations using a RL agent trained using the Proximal Policy Optimization algorithm. Dynamical nonlinear systems of many coupled neurons are especially hard to control because of their very different responses to weak and strong stimuli, so the approch was adjusted to use multiple auxiliary PPO agents, trained on various neuronal patterns. This multi agent approach desynchronized the ensemble more than the performance of a single model. In the futrue this and other approaches can personalize the treatement for patients with different signaling patterns and at different progression stages of the disease.\n",
    "\n",
    "The paper highlights the importance of standardizing evaluation methods for different control algorithms. The proposed RL-based gym environment offers a unified platform for developing and testing diverse stimulation strategies, including pulsatile and adaptive feedback loops. The authors emphasize the potential of RL as a universal, data-driven approach that could be integrated into real-world DBS devices for personalized, “smart” stimulation to manage Parkinson’s symptoms.\n",
    "\n",
    "### Background literature\n",
    "Recent advancements in neuroscience and machine learning have leveraged reinforcement learning (RL) to better understand and control neural activity, particularly in the context of neurological disorders and motor behavior.\n",
    "Synchronous activity of malfunctioning neurons is reportedly a cause of many neurological disorders such as Parkinson’s disease. Learning how to manipulate this collective synchronous activity is critical for neuroscience but the barrier of needing to test with live human brains is challenging. To address this, a simulated RL gym framework was developed to emulate the synchronous activity of degenerate neuron ensembles. This enables researchers to find viable suppression parameters for the modeled neurons. Using a combination of RL and multiple Proximal Policy Optimization (PPO) agents, the framework demonstrated robustness to noise. The RL-base suppression demonstrated successful synchrony suppression for regular, chaotic, and bursting collective oscillation, without having prior knowledge about the neuronal ensemble model. The main advantage of the RL-based suppression method is that it is data-driven and universal, making it an ideal candidate for clinical approval as a “smart” control algorithm to be embedded into deep brain stimulation devices. This method could be implemented in an experimental setting by taking the characteristics of current measuring and stimulating equipment limitations into account<a name=\"krylov\"></a>[<sup>[1]</sup>](#krylovnote).\n",
    "\n",
    "Deep Brain Stimulation (DBS) is a technique of electrical stimulation of brain tissue used as a therapy for managing neurological disorders such as Parkinson’s disease. Traditional DBS systems deliver fixed-frequency electrical stimulation, but individualized parameter adjustments are critical for optimizing treatment. A novel Basal Ganglia Reinforcement Learning (BGRL) framework was developed to address this limitation by incorporating an actor-critic RL architecture inspired by the Basal Ganglia’s neural circuits. BGRL features a closed-loop feedback mechanism that adjusts stimulation to suppress neural synchrony, particularly during regular, chaotic, and bursting signaling regimes. Compared to the soft actor-critic model, BGRL achieved substantial reductions in neural synchrony (40%, 146%, and 40% across the three regimes) and improved energy efficiency. The experiments have been conducted under specific conditions in the OpenAI Gym environment and are yet to be tested for a diverse patient population or different neurological disorders. As with many RL algorithms, BGRL algorithms can be time-consuming and computationally intensive due to complexity and the need to optimize its performance, critical to the algorithm’s effectiveness. Since DBS are engraved in the brain for a long time, this algorithm can prove to be effective but not as much over short time periods<a name=\"agarwal\"></a>[<sup>[2]</sup>](#agarwalnote).\n",
    "\n",
    "Besides the possibility of soothing brain activity directly, RL and simulations are great tools for understanding how the brain actually controls our physical behavior. Animals have fine motor control enabling their varied range of behaviors. Simply looking at the brain gives little clue how this detail control is implemented. To better understand, models that relate principles of control to the structure of neural activity in behaving animals have been built. A biomechanically realistic virtual rodent, actuated by a deep RL-trained artificial neural network, was developed to mimic freely moving rats. This model allowed for comparisons between neural activity in real rats and the virtual rodent’s neural network. The neural activity in the sensorimotor striatum and motor cortex was more accurately predicted by the virtual rodent’s network than by physical movement features in the real rat’s movement, supporting the idea that these brain regions implement inverse dynamics. The virtual rodent’s network also exhibited latent variability that mirrored neural variability in the observed animals and provided robustness. This simulation-based approach can help bridge theoretical principles of motor control and empirical observations of neural activity across behavior<a name=\"aldarondo\"></a>[<sup>[3]</sup>](#aldarondonote).\n",
    "\n",
    "\n",
    "### Lecture description\n",
    "Include some details of what will be covered by traditional lecture.  A slide running order is ideal here, but probably unrealistic.  Include information about how you will apportion coverage between group members.\n",
    "- Introductions of ourselves and the topic\n",
    "    - Neuroscience basis of algorithms (Mabel)  \n",
    "        - Quick review of neuroanatomy and how that shaped algorithms such as neural nets and reinforcement learning (Neurons, action potentials that can be all or nothing like binary or graded)\n",
    "    - Neurological disorders (Rina)\n",
    "        - Ways brain activity that is affected by neurological and non-neurological disorders - synchronous activity of damaged neurons  \n",
    "    - Explanation of current medical interventions using these algorithms  (Mabel)\n",
    "        - Stimulate the brain with electricity (what is deep brain stimulation, and other things like mri and things used to monitor or stimulate the brain)\n",
    "    - Simulations of the brain using RL (Mabel)\n",
    "        - Overview - pull from the readings\n",
    "        - Review of reinforcement learning math\n",
    "        - Mini exercise?\n",
    "    - Interventions for neurological disorders using RL (Rina)\n",
    "        - First case we will be examining - \n",
    "        - Math\n",
    "        - Mini exercise \n",
    "        - Second case we will be examining - \n",
    "        - Math\n",
    "        - Questions/discussion \n",
    "\n",
    "\n",
    "### Active learning\n",
    "Include information about any discussions or exercises you will have students do.  Each active learning exercise needs 1 to 3 short paragraphs.  It should include \n",
    "- the element of the outline this will cover\n",
    "- brief description of framework you will provide to set off the discussion OR a description of the in class exercise\n",
    "- for how long maximum will this run? \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates\n",
    "Different dates we would be happy to run your class in descending order of preference\n",
    "- March 14\n",
    "- March 12\n",
    "- March 10\n",
    "- March 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Participates and are mentally present in team meetings*\n",
    "* *Communicates with team on the status of their part of the project and if any roadblocks or conflicts occur*\n",
    "* *Build off of ideas instead of tearing them down*\n",
    "* *Understand and respect each others' preferences for communication, and clearly articulate own preferences*\n",
    "* *Uphold standards of integrity and quality when developing code, citing sources used*\n",
    "* *Create an environment where people are comfortable reaching out for help*\n",
    "* *Reach out for help as soon as possible when it is needed, and treat everyone and their tasks as equally important to the success of the team*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/12  |  2 PM |  Brainstorm topics for the presentation (all) and work on project proposal  | Determine best form of communication; Discuss and decide on final project topic; discuss subtopics for each person to teach; begin background research, fill out project proposal for submission | \n",
    "| 2/19  |  2 PM |  submit project proposal (2/15 latest) Do background research on topic (all) find readings that support topic | Discuss research; work on outline for teaching to send to professor for review | \n",
    "| 2/26  | 2 PM  | start on slide deck and the in class exercises Implement feedback from professor (all) | Discuss slides and test each other’s programming exercises |\n",
    "| 3/5  | 2 PM  | update slides and programming exercises and write quiz questions (all) | Review slides, programming exercises, and quiz questions, compile updates and send to professor to review |\n",
    "| 3/12  | 3 PM  | Finalize slides, programming exercises, quiz questions Practice presentation individually (each person gets an equal amount of time) Implement feedback from professor (all) | final presentation in class |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"krylovnote\"></a>1.[^](#krylov): Krylov, D., Tachet, R., Laroche, R., Rosenblum, M., & Dylov, D. V. (2020). Reinforcement learning framework for deep brain stimulation study. arXiv preprint arXiv:2002.10948. https://arxiv.org/abs/2002.10948<br> \n",
    "<a name=\"agarwalnote\"></a>2.[^](#agarwal): Agarwal, H., & Rathore, H. (2024). BGRL: Basal Ganglia inspired Reinforcement Learning based framework for deep brain stimulators. Artificial Intelligence in Medicine, 147, 102736.https://www.sciencedirect.com/science/article/pii/S0933365723002506#d1e511<br> \n",
    "<a name=\"aldarondonote\"></a>3.[^](#aldarondo): Aldarondo, D., Merel, J., Marshall, J. D., Hasenclever, L., Klibaite, U., Gellis, A., ... & Ölveczky, B. P. (2024). A virtual rodent predicts the structure of neural activity across behaviors. *Nature*, 1-3. https://www.nature.com/articles/s41586-024-07633-4<br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 (default, Jul 27 2021, 07:03:16) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
